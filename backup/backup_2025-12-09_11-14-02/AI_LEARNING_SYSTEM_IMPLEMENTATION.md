# AI Learning System Implementation Guide
## Reinforcement Learning from Human Feedback (RLHF)

**Created:** December 2, 2025  
**Status:** In Progress  
**Goal:** Make the AI Agent learn from staff feedback and improve over time

---

## ðŸŽ¯ Overview

This system captures staff feedback on AI-generated draft responses and uses it to continuously improve the AI's performance. Every time staff edit, approve, or reject an AI draft, the system learns.

---

## âœ… What's Been Built

### 1. **Enhanced System Prompt** âœ…
- **File:** `packages/customer-service-agent/src/CustomerServiceAgent.ts`
- **Changes:** Added specific examples for common scenarios (thank you, how to order, where's my order, problems)
- **Impact:** AI now has better context and examples to follow

### 2. **Database Schema for Learning** âœ…
- **File:** `packages/worker/migrations/0015_add_ai_learning_feedback.sql`
- **New Fields in `ai_draft_responses`:**
  - `quality_score` (1-5 stars)
  - `edit_distance` (how much was changed)
  - `was_helpful` (boolean)
  - `improvement_notes` (text feedback)
  - `feedback_submitted_at` / `feedback_submitted_by`
- **New Table:** `ai_learning_examples` - stores high-quality responses for training

### 3. **Feedback UI Modal** âœ…
- **File:** `packages/customer-service-dashboard/src/components/AIDraftFeedbackModal.tsx`
- **Features:**
  - 5-star rating system
  - Yes/No helpful indicator
  - Optional improvement notes
  - Beautiful, easy-to-use interface

### 4. **API Endpoint for Feedback** âœ…
- **File:** `packages/worker/src/controllers/tickets.ts`
- **Endpoint:** `POST /api/tickets/:id/ai-draft/feedback`
- **Logic:**
  - Captures feedback
  - Calculates edit distance
  - Auto-adds 4-5 star responses to learning examples
  - Stores for analytics

### 5. **Frontend API Integration** âœ…
- **File:** `packages/customer-service-dashboard/src/lib/api.ts`
- **Method:** `submitAIDraftFeedback()`

---

## ðŸš§ What Needs to Be Done

### **STEP 1: Add OpenAI API Key** (USER ACTION REQUIRED)

```powershell
cd D:\coding\DARTMOUTH_OS_PROJECT\packages\worker
npx wrangler secret put OPENAI_API_KEY
```

**Get your key:** https://platform.openai.com/api-keys  
**Recommended Model:** GPT-4o (fastest, smartest)

---

### **STEP 2: Run Database Migration**

```powershell
cd D:\coding\DARTMOUTH_OS_PROJECT\packages\worker
npx wrangler d1 execute agent-army-db --remote --file=./migrations/0015_add_ai_learning_feedback.sql
```

---

### **STEP 3: Integrate Feedback Modal into Ticket Detail Page**

**File to modify:** `packages/customer-service-dashboard/src/pages/TicketDetailPage.tsx`

**Add these changes:**

1. Import the modal:
```typescript
import { AIDraftFeedbackModal } from '../components/AIDraftFeedbackModal'
```

2. Add state:
```typescript
const [showFeedbackModal, setShowFeedbackModal] = useState(false)
const [feedbackDraftId, setFeedbackDraftId] = useState<string | null>(null)
```

3. Add feedback handler:
```typescript
const handleSubmitFeedback = async (feedback: {
  qualityScore: number
  wasHelpful: boolean
  improvementNotes: string
}) => {
  if (!id) return
  try {
    await ticketsApi.submitAIDraftFeedback(id, feedback)
    setShowFeedbackModal(false)
  } catch (error: any) {
    console.error('Failed to submit feedback:', error)
    alert(`Failed to submit feedback: ${error.response?.data?.error || error.message}`)
  }
}
```

4. Show modal after approve/edit:
```typescript
// In handleApproveAIDraft and handleEditAIDraft, add:
setShowFeedbackModal(true)
setFeedbackDraftId(aiDraftData?.draft?.id)
```

5. Add modal to JSX (before closing div):
```typescript
<AIDraftFeedbackModal
  isOpen={showFeedbackModal}
  onClose={() => setShowFeedbackModal(false)}
  onSubmit={handleSubmitFeedback}
  draftId={feedbackDraftId || ''}
/>
```

---

### **STEP 4: Create AI Performance Analytics Dashboard**

**New File:** `packages/customer-service-dashboard/src/pages/AIAnalyticsPage.tsx`

**Metrics to show:**
- **AI Smartness Score** (0-100%) - based on approval rate and quality scores
- **Weekly Improvement** - how much smarter the AI got this week
- **Approval Rate** - % of drafts sent without edits
- **Average Quality Score** - average star rating
- **Time Saved** - estimated hours saved by AI drafts
- **Learning Examples** - count of high-quality responses captured
- **Top Performing Intents** - which types of messages AI handles best
- **Areas for Improvement** - which intents have low scores

---

### **STEP 5: Build Learning Pipeline**

**New File:** `packages/worker/src/services/AILearningService.ts`

**Functions needed:**
1. `analyzeWeeklyPerformance()` - calculate metrics
2. `extractBestResponses()` - find top-rated responses
3. `updateSystemPrompt()` - add new examples to prompt
4. `generateWeeklyReport()` - create performance report

---

## ðŸ“Š How the Learning Loop Works

```
1. Customer sends email
   â†“
2. AI generates draft response
   â†“
3. Staff reviews draft
   â†“
4. Staff edits/approves/rejects
   â†“
5. Feedback modal appears
   â†“
6. Staff rates quality (1-5 stars)
   â†“
7. System captures:
   - Quality score
   - Edit distance
   - Was helpful?
   - Improvement notes
   â†“
8. If 4-5 stars â†’ Add to learning examples
   â†“
9. Weekly: Analyze all feedback
   â†“
10. Update system prompt with best examples
   â†“
11. AI gets smarter! ðŸ§ 
```

---

## ðŸ“ˆ Expected Improvement Timeline

### **Week 1: Baseline**
- AI Smartness: 30-40%
- Approval Rate: 10-20%
- Most drafts need heavy editing

### **Week 2-3: Initial Learning**
- AI Smartness: 45-55%
- Approval Rate: 25-35%
- AI learns common patterns

### **Week 4-6: Rapid Improvement**
- AI Smartness: 60-75%
- Approval Rate: 40-60%
- AI handles routine inquiries well

### **Week 8-12: Maturity**
- AI Smartness: 75-85%
- Approval Rate: 60-80%
- AI handles most inquiries with minimal edits

### **Month 6+: Expert Level**
- AI Smartness: 85-95%
- Approval Rate: 80-90%
- AI only escalates complex/sensitive issues

---

## ðŸŽ¯ Success Metrics

**Track these weekly:**
1. **Approval Rate** - % of drafts sent without changes
2. **Quality Score** - average star rating
3. **Time Saved** - hours saved by AI assistance
4. **Learning Examples** - count of high-quality responses
5. **Confidence Accuracy** - does AI confidence match actual quality?

---

## ðŸš€ Deployment Steps

1. âœ… Add OpenAI API key (user action)
2. âœ… Run migration
3. âœ… Deploy worker: `npx wrangler deploy`
4. âœ… Integrate feedback modal into TicketDetailPage
5. âœ… Build dashboard: `npm run build`
6. âœ… Deploy dashboard: `npx wrangler pages deploy dist --project-name=customer-service-dashboard`
7. âœ… Test with real tickets
8. âœ… Monitor analytics

---

## ðŸ“š Next Steps (Post-Implementation)

1. **Add RAG Documents** - Upload product guides, FAQs, policies
2. **Connect Shopify** - Real-time order data
3. **Connect PERP** - Production tracking
4. **Build Analytics Dashboard** - Visualize AI performance
5. **Automate Learning** - Weekly auto-updates to system prompt
6. **A/B Testing** - Test different prompts to find what works best

---

## ðŸ”— Related Documents

- Architecture: `McCarthy AI Dartmouth OS 2-12-25/DARTMOUTH_OS_BLUEPRINT_2025.md`
- API Docs: `McCarthy AI Dartmouth OS 2-12-25/MASTER_API_ARCHITECTURE.md`
- Project Status: `McCarthy AI Dartmouth OS 2-12-25/PROJECT_STATUS_DEC_2_2025.md`

---

## ðŸ’¡ Key Insights

**Why this works:**
- Staff feedback is the BEST training data
- Every edit teaches the AI what good looks like
- High-quality responses become templates
- System improves automatically over time
- No manual training required

**The magic:**
- AI learns YOUR business's voice
- AI learns YOUR products/services
- AI learns YOUR customer base
- AI gets better at YOUR specific use cases

---

**Status:** Ready for deployment pending OpenAI API key addition
**Next Action:** User adds OpenAI API key, then we deploy everything

